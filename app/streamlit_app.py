"""Streamlit UI ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª"""
import streamlit as st
from streamlit_autorefresh import st_autorefresh
import pandas as pd
import json
import os
import re
from datetime import datetime, timedelta
from pathlib import Path

st.set_page_config(
    page_title="AIåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“Š",
    layout="wide",
)

# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦– ===

PARAMS_FILE = Path("input/params.json")

def load_params_from_file():
    """å¤–éƒ¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    if not PARAMS_FILE.exists():
        return None, None, []
    try:
        mtime = PARAMS_FILE.stat().st_mtime
        with open(PARAMS_FILE, "r", encoding="utf-8") as f:
            raw_params = json.load(f)
        params, errors = validate_params(raw_params)
        return params, mtime, errors
    except json.JSONDecodeError as e:
        return None, None, [{
            "error_code": "INVALID_JSON",
            "message": f"Invalid JSON: {e}",
            "path": "$",
            "hint": "Fix JSON syntax in input/params.json."
        }]
    except IOError as e:
        return None, None, [{
            "error_code": "FILE_IO_ERROR",
            "message": f"Failed to read params.json: {e}",
            "path": "$",
            "hint": "Check file permissions and file path."
        }]

def apply_params_to_session(params):
    """èª­ã¿è¾¼ã‚“ã ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«åæ˜ ï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®keyã‚‚æ›´æ–°ï¼‰"""
    if params is None:
        return False

    st.session_state["loaded_params"] = params
    st.session_state["params_applied"] = True

    # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®keyã‚’ç›´æ¥æ›´æ–°ï¼ˆã“ã‚Œã§UIã«å³åº§ã«åæ˜ ã•ã‚Œã‚‹ï¼‰
    source = params.get("source", "ga4").lower()

    # æ—¥ä»˜
    date_range = params.get("date_range", {})
    if date_range.get("start"):
        st.session_state["w_start_date"] = datetime.strptime(date_range["start"], "%Y-%m-%d").date()
    if date_range.get("end"):
        st.session_state["w_end_date"] = datetime.strptime(date_range["end"], "%Y-%m-%d").date()

    # å–å¾—ä»¶æ•°
    if "limit" in params:
        st.session_state["w_limit"] = params["limit"]

    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
    if "dimensions" in params:
        if source == "gsc":
            st.session_state["w_gsc_dimensions"] = params["dimensions"]
        else:
            st.session_state["w_ga4_dimensions"] = params["dimensions"]

    # GA4å›ºæœ‰
    if source == "ga4":
        if "property_id" in params:
            st.session_state["w_ga4_property_id"] = params["property_id"]
        if "metrics" in params:
            st.session_state["w_ga4_metrics"] = params["metrics"]
        if "filter_d" in params:
            st.session_state["w_ga4_filter"] = params["filter_d"]

    # GSCå›ºæœ‰
    if source == "gsc":
        if "site_url" in params:
            st.session_state["w_gsc_site"] = params["site_url"]
        if "filter" in params:
            st.session_state["w_gsc_filter"] = params["filter"]

    # BigQueryå›ºæœ‰
    if source == "bigquery":
        if "project_id" in params:
            st.session_state["w_bq_project"] = params["project_id"]
        if "sql" in params:
            st.session_state["w_bq_sql"] = params["sql"]

    return True

def check_file_updated():
    """ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not PARAMS_FILE.exists():
        return False

    current_mtime = PARAMS_FILE.stat().st_mtime
    last_mtime = st.session_state.get("last_params_mtime", 0)

    if current_mtime > last_mtime:
        st.session_state["last_params_mtime"] = current_mtime
        return True
    return False

# === å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ===
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from lib.megaton_client import (
    get_megaton,
    get_ga4_properties as _get_ga4_properties,
    query_ga4,
    get_gsc_sites as _get_gsc_sites,
    query_gsc,
    get_bq_datasets as _get_bq_datasets,
    query_bq,
    save_to_sheet,
)
from lib.params_validator import validate_params

# Streamlitç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ©ãƒƒãƒ‘ãƒ¼
@st.cache_data(ttl=300)
def get_ga4_properties():
    return _get_ga4_properties()

@st.cache_data(ttl=300)
def get_gsc_sites():
    return _get_gsc_sites()

@st.cache_data(ttl=300)
def get_bq_datasets(project_id):
    return _get_bq_datasets(project_id)

@st.cache_data(ttl=60)
def execute_ga4_query(property_id, start_date, end_date, dimensions, metrics, filter_d, limit):
    return query_ga4(property_id, start_date, end_date, dimensions, metrics, filter_d, limit)

@st.cache_data(ttl=60)
def execute_gsc_query(site_url, start_date, end_date, dimensions, limit, dimension_filter=None):
    return query_gsc(site_url, start_date, end_date, dimensions, limit, dimension_filter)

def parse_gsc_filter(filter_str: str):
    """GSCãƒ•ã‚£ãƒ«ã‚¿æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆAPIç”¨ï¼‰"""
    if not filter_str or not filter_str.strip():
        return None
    filters = []
    for part in filter_str.split(";"):
        parts = part.split(":", 2)
        if len(parts) == 3:
            filters.append({
                "dimension": parts[0],
                "operator": parts[1],
                "expression": parts[2]
            })
    return filters if filters else None


# === ãƒ•ã‚£ãƒ«ã‚¿ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ===

# GA4æ¼”ç®—å­
GA4_OPERATORS = ["==", "!=", "=@", "!@", "=~", "!~", ">", ">=", "<", "<="]
GA4_OPERATOR_LABELS = {
    "==": "ç­‰ã—ã„",
    "!=": "ç­‰ã—ããªã„", 
    "=@": "å«ã‚€",
    "!@": "å«ã¾ãªã„",
    "=~": "æ­£è¦è¡¨ç¾ä¸€è‡´",
    "!~": "æ­£è¦è¡¨ç¾ä¸ä¸€è‡´",
    ">": "ã‚ˆã‚Šå¤§ãã„",
    ">=": "ä»¥ä¸Š",
    "<": "ã‚ˆã‚Šå°ã•ã„",
    "<=": "ä»¥ä¸‹",
}

# GSCæ¼”ç®—å­
GSC_OPERATORS = ["contains", "notContains", "equals", "notEquals", "includingRegex", "excludingRegex"]
GSC_OPERATOR_LABELS = {
    "contains": "å«ã‚€",
    "notContains": "å«ã¾ãªã„",
    "equals": "ç­‰ã—ã„",
    "notEquals": "ç­‰ã—ããªã„",
    "includingRegex": "æ­£è¦è¡¨ç¾ä¸€è‡´",
    "excludingRegex": "æ­£è¦è¡¨ç¾ä¸ä¸€è‡´",
}


def parse_ga4_filter_to_df(filter_str: str) -> pd.DataFrame:
    """GA4ãƒ•ã‚£ãƒ«ã‚¿æ–‡å­—åˆ—ã‚’DataFrameã«ãƒ‘ãƒ¼ã‚¹"""
    if not filter_str or not filter_str.strip():
        return pd.DataFrame(columns=["å¯¾è±¡", "æ¼”ç®—å­", "å€¤"])
    
    rows = []
    for part in filter_str.split(";"):
        part = part.strip()
        if not part:
            continue
        # æ¼”ç®—å­ã§ãƒãƒƒãƒï¼ˆé•·ã„é †ã«è©¦ã™ï¼‰
        for op in sorted(GA4_OPERATORS, key=len, reverse=True):
            if op in part:
                idx = part.index(op)
                field = part[:idx]
                value = part[idx + len(op):]
                rows.append({"å¯¾è±¡": field, "æ¼”ç®—å­": op, "å€¤": value})
                break
    
    return pd.DataFrame(rows) if rows else pd.DataFrame(columns=["å¯¾è±¡", "æ¼”ç®—å­", "å€¤"])


def serialize_ga4_filter_from_df(df: pd.DataFrame) -> str:
    """DataFrameã‹ã‚‰GA4ãƒ•ã‚£ãƒ«ã‚¿æ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
    if df is None or df.empty:
        return ""
    parts = []
    for _, row in df.iterrows():
        if row["å¯¾è±¡"] and row["æ¼”ç®—å­"] and row["å€¤"]:
            parts.append(f"{row['å¯¾è±¡']}{row['æ¼”ç®—å­']}{row['å€¤']}")
    return ";".join(parts)


def parse_gsc_filter_to_df(filter_str: str) -> pd.DataFrame:
    """GSCãƒ•ã‚£ãƒ«ã‚¿æ–‡å­—åˆ—ã‚’DataFrameã«ãƒ‘ãƒ¼ã‚¹"""
    if not filter_str or not filter_str.strip():
        return pd.DataFrame(columns=["å¯¾è±¡", "æ¼”ç®—å­", "å€¤"])
    
    rows = []
    for part in filter_str.split(";"):
        parts = part.split(":", 2)
        if len(parts) == 3:
            rows.append({"å¯¾è±¡": parts[0], "æ¼”ç®—å­": parts[1], "å€¤": parts[2]})
    
    return pd.DataFrame(rows) if rows else pd.DataFrame(columns=["å¯¾è±¡", "æ¼”ç®—å­", "å€¤"])


def serialize_gsc_filter_from_df(df: pd.DataFrame) -> str:
    """DataFrameã‹ã‚‰GSCãƒ•ã‚£ãƒ«ã‚¿æ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
    if df is None or df.empty:
        return ""
    parts = []
    for _, row in df.iterrows():
        if row["å¯¾è±¡"] and row["æ¼”ç®—å­"] and row["å€¤"]:
            parts.append(f"{row['å¯¾è±¡']}:{row['æ¼”ç®—å­']}:{row['å€¤']}")
    return ";".join(parts)


def execute_bq_query(project_id, sql):
    return query_bq(project_id, sql)


# === UI ===

st.title("ğŸ“Š AIåˆ†æã‚¢ãƒ—ãƒª")

# === ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ===

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "auto_watch" not in st.session_state:
    st.session_state["auto_watch"] = True
if "auto_execute" not in st.session_state:
    st.session_state["auto_execute"] = False
if "params_validation_errors" not in st.session_state:
    st.session_state["params_validation_errors"] = []

# è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ç”¨ï¼š2ç§’ã”ã¨ï¼‰
if st.session_state.get("auto_watch", True):
    st_autorefresh(interval=2000, limit=None, key="file_watcher_refresh")

# ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒã‚§ãƒƒã‚¯ç”¨ãƒ•ãƒ©ã‚°
file_just_updated = False

# ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§å®Ÿè¡Œï¼‰
if st.session_state.get("auto_watch", True) and check_file_updated():
    params, _, errors = load_params_from_file()
    if params:
        apply_params_to_session(params)
        st.session_state["params_validation_errors"] = []
        st.toast("ğŸ”„ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ", icon="ğŸ“„")
        file_just_updated = True
        if st.session_state.get("auto_execute", False):
            st.session_state["auto_execute_pending"] = True
    elif errors:
        st.session_state["params_validation_errors"] = errors
        st.toast("âŒ params.json ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ", icon="âš ï¸")

with st.sidebar:
    with st.expander("ğŸ¤– AI Agent é€£æº", expanded=True):
        st.session_state["auto_watch"] = st.toggle(
            "JSONè‡ªå‹•åæ˜ ",
            value=st.session_state.get("auto_watch", True),
            help="input/params.json ã®å¤‰æ›´ã‚’2ç§’ã”ã¨ã«æ¤œçŸ¥"
        )
        st.session_state["auto_execute"] = st.toggle(
            "è‡ªå‹•å®Ÿè¡Œ",
            value=st.session_state.get("auto_execute", False),
            help="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¾Œã«è‡ªå‹•ã§ã‚¯ã‚¨ãƒªå®Ÿè¡Œ"
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹è¡¨ç¤º
        if PARAMS_FILE.exists():
            mtime = datetime.fromtimestamp(PARAMS_FILE.stat().st_mtime)
            st.caption(f"ğŸ“„ params.json: {mtime.strftime('%H:%M:%S')} æ›´æ–°")
        else:
            st.caption("ğŸ“„ params.json: ãªã—")

        # æ‰‹å‹•èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
        if st.button("ğŸ“¥ JSONã‚’é–‹ã", use_container_width=True):
            params, mtime, errors = load_params_from_file()
            if params:
                apply_params_to_session(params)
                st.session_state["last_params_mtime"] = mtime
                st.session_state["params_validation_errors"] = []
                st.success("âœ“ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.rerun()
            elif errors:
                st.session_state["params_validation_errors"] = errors
                st.error("params.json ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                st.warning("params.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("è¨­å®š")

    validation_errors = st.session_state.get("params_validation_errors", [])
    if validation_errors:
        st.error("params.json ãŒã‚¹ã‚­ãƒ¼ãƒä¸ä¸€è‡´ã§ã™")
        for err in validation_errors:
            st.caption(f"`{err['error_code']}` {err['path']} - {err['message']}")

    # èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    lp = st.session_state.get("loaded_params", {})

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åæ˜ æ™‚ã®é€šçŸ¥
    if st.session_state.get("params_applied"):
        st.info("ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åæ˜ ã—ã¾ã—ãŸ")
        st.session_state["params_applied"] = False

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    source_map = {"ga4": "GA4", "gsc": "GSC", "bigquery": "BigQuery"}
    default_source = source_map.get(lp.get("source", "ga4").lower(), "GA4")
    source = st.radio("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", ["GA4", "GSC", "BigQuery"], horizontal=True,
                      index=["GA4", "GSC", "BigQuery"].index(default_source))

    st.divider()

    # BigQueryä»¥å¤–ã¯æ—¥ä»˜ç¯„å›²ã‚’è¡¨ç¤º
    if source != "BigQuery":
        # æ—¥ä»˜ç¯„å›²ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        if "w_start_date" not in st.session_state:
            date_range = lp.get("date_range", {})
            st.session_state["w_start_date"] = datetime.strptime(date_range["start"], "%Y-%m-%d").date() if date_range.get("start") else (datetime.now() - timedelta(days=14)).date()
            st.session_state["w_end_date"] = datetime.strptime(date_range["end"], "%Y-%m-%d").date() if date_range.get("end") else (datetime.now() - timedelta(days=1)).date()

        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("é–‹å§‹æ—¥", key="w_start_date")
        with col2:
            end_date = st.date_input("çµ‚äº†æ—¥", key="w_end_date")

        st.divider()

    if source == "GA4":
        # GA4è¨­å®š
        properties = get_ga4_properties()
        property_options = {p["display"]: p["id"] for p in properties}

        # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£IDã‹ã‚‰displayåã‚’é€†å¼•ãï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã¾ãŸã¯loaded_paramsã‹ã‚‰ï¼‰
        default_prop_idx = 0
        loaded_prop_id = st.session_state.get("w_ga4_property_id") or lp.get("property_id", "")
        for i, (display, pid) in enumerate(property_options.items()):
            if pid == loaded_prop_id:
                default_prop_idx = i
                break

        selected_property = st.selectbox("ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£", list(property_options.keys()), index=default_prop_idx)
        property_id = property_options[selected_property]

        # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆåˆæœŸåŒ–ï¼‰
        all_dimensions = ["date", "sessionDefaultChannelGroup", "sessionSource", "sessionMedium",
                         "pagePath", "landingPage", "deviceCategory", "country"]
        if "w_ga4_dimensions" not in st.session_state:
            st.session_state["w_ga4_dimensions"] = lp.get("dimensions", ["date"]) if lp.get("source", "").lower() == "ga4" else ["date"]
        dimensions = st.multiselect("ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³", all_dimensions, key="w_ga4_dimensions")

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆåˆæœŸåŒ–ï¼‰
        all_metrics = ["sessions", "activeUsers", "newUsers", "screenPageViews",
                      "bounceRate", "averageSessionDuration", "conversions"]
        if "w_ga4_metrics" not in st.session_state:
            st.session_state["w_ga4_metrics"] = lp.get("metrics", ["sessions", "activeUsers"]) if lp.get("source", "").lower() == "ga4" else ["sessions", "activeUsers"]
        metrics = st.multiselect("ãƒ¡ãƒˆãƒªã‚¯ã‚¹", all_metrics, key="w_ga4_metrics")

        # ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆåˆæœŸåŒ–ï¼‰
        if "w_ga4_filter" not in st.session_state:
            st.session_state["w_ga4_filter"] = lp.get("filter_d", "") if lp.get("source", "").lower() == "ga4" else ""
        
        # ãƒ•ã‚£ãƒ«ã‚¿ã‚’DataFrameã«ãƒ‘ãƒ¼ã‚¹
        filter_df = parse_ga4_filter_to_df(st.session_state.get("w_ga4_filter", ""))
        
        with st.expander("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶", expanded=bool(len(filter_df))):
            # ã‚ˆãä½¿ã†ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            ga4_filter_dims = ["sessionDefaultChannelGroup", "sessionSource", "sessionMedium", 
                               "pagePath", "landingPage", "deviceCategory", "country", "city"]
            
            edited_filter_df = st.data_editor(
                filter_df,
                column_config={
                    "å¯¾è±¡": st.column_config.SelectboxColumn(
                        "å¯¾è±¡",
                        options=ga4_filter_dims + dimensions,
                        required=True,
                    ),
                    "æ¼”ç®—å­": st.column_config.SelectboxColumn(
                        "æ¼”ç®—å­",
                        options=GA4_OPERATORS,
                        required=True,
                    ),
                    "å€¤": st.column_config.TextColumn("å€¤", required=True),
                },
                num_rows="dynamic",
                use_container_width=True,
                key="ga4_filter_editor"
            )
            
            # DataFrameã‹ã‚‰æ–‡å­—åˆ—ã«å¤‰æ›
            filter_d = serialize_ga4_filter_from_df(edited_filter_df)
            st.session_state["w_ga4_filter"] = filter_d
            
            if filter_d:
                st.caption(f"ğŸ“ `{filter_d}`")

    elif source == "GSC":
        # GSCè¨­å®š
        sites = get_gsc_sites()

        # ã‚µã‚¤ãƒˆURLã®åˆæœŸé¸æŠï¼ˆkeyã‚’ä½¿ã£ã¦åˆ¶å¾¡ï¼‰
        if "w_gsc_site" not in st.session_state:
            loaded_site_url = lp.get("site_url", "")
            if loaded_site_url in sites:
                st.session_state["w_gsc_site"] = loaded_site_url
            elif sites:
                st.session_state["w_gsc_site"] = sites[0]

        site_url = st.selectbox("ã‚µã‚¤ãƒˆ", sites, key="w_gsc_site")

        # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆåˆæœŸåŒ–ï¼‰
        all_gsc_dims = ["query", "page", "country", "device", "date"]
        if "w_gsc_dimensions" not in st.session_state:
            st.session_state["w_gsc_dimensions"] = lp.get("dimensions", ["query"]) if lp.get("source", "").lower() == "gsc" else ["query"]
        dimensions = st.multiselect("ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³", all_gsc_dims, key="w_gsc_dimensions")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆåˆæœŸåŒ–ï¼‰
        if "w_gsc_filter" not in st.session_state:
            st.session_state["w_gsc_filter"] = lp.get("filter", "") if lp.get("source", "").lower() == "gsc" else ""
        
        # ãƒ•ã‚£ãƒ«ã‚¿ã‚’DataFrameã«ãƒ‘ãƒ¼ã‚¹
        gsc_filter_df = parse_gsc_filter_to_df(st.session_state.get("w_gsc_filter", ""))
        
        with st.expander("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶", expanded=bool(len(gsc_filter_df))):
            gsc_filter_dims = ["query", "page", "country", "device", "date"]
            
            edited_gsc_filter_df = st.data_editor(
                gsc_filter_df,
                column_config={
                    "å¯¾è±¡": st.column_config.SelectboxColumn(
                        "å¯¾è±¡",
                        options=gsc_filter_dims,
                        required=True,
                    ),
                    "æ¼”ç®—å­": st.column_config.SelectboxColumn(
                        "æ¼”ç®—å­",
                        options=GSC_OPERATORS,
                        required=True,
                    ),
                    "å€¤": st.column_config.TextColumn("å€¤", required=True),
                },
                num_rows="dynamic",
                use_container_width=True,
                key="gsc_filter_editor"
            )
            
            # DataFrameã‹ã‚‰æ–‡å­—åˆ—ã«å¤‰æ›
            gsc_filter = serialize_gsc_filter_from_df(edited_gsc_filter_df)
            st.session_state["w_gsc_filter"] = gsc_filter
            
            if gsc_filter:
                st.caption(f"ğŸ“ `{gsc_filter}`")

    else:
        # BigQueryè¨­å®š
        if "w_bq_project" not in st.session_state:
            st.session_state["w_bq_project"] = lp.get("project_id", "")
        bq_project = st.text_input("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID", key="w_bq_project")

    # å–å¾—ä»¶æ•°ï¼ˆBigQueryä»¥å¤–ï¼‰
    if source != "BigQuery":
        if "w_limit" not in st.session_state:
            st.session_state["w_limit"] = lp.get("limit", 1000)
        # ã‚«ãƒ³ãƒå½¢å¼ã§é¸æŠè‚¢ã‚’è¡¨ç¤º
        limit_options = [100, 500, 1000, 5000, 10000, 25000, 50000, 100000]
        limit_labels = {v: f"{v:,}" for v in limit_options}
        
        # ç¾åœ¨å€¤ãŒé¸æŠè‚¢ã«ãªã„å ´åˆã¯æœ€ã‚‚è¿‘ã„å€¤ã‚’é¸æŠ
        current_limit = st.session_state.get("w_limit", 1000)
        if current_limit not in limit_options:
            current_limit = min(limit_options, key=lambda x: abs(x - current_limit))
        
        limit = st.select_slider(
            "å–å¾—ä»¶æ•°",
            options=limit_options,
            value=current_limit,
            format_func=lambda x: limit_labels[x],
            key="w_limit"
        )

    st.divider()

    execute_btn = st.button("ğŸš€ å®Ÿè¡Œ", type="primary", use_container_width=True)

# è‡ªå‹•å®Ÿè¡Œãƒã‚§ãƒƒã‚¯
auto_execute_pending = st.session_state.get("auto_execute_pending", False)
if auto_execute_pending:
    st.session_state["auto_execute_pending"] = False  # ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢

# BigQuery SQLå…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«è¡¨ç¤ºï¼‰
if source == "BigQuery":
    st.subheader("SQL ã‚¯ã‚¨ãƒª")
    
    # ã‚µãƒ³ãƒ—ãƒ«SQL
    sample_sql = """SELECT 
    event_date,
    COUNT(*) as event_count
FROM `project.analytics_123456789.events_*`
WHERE _TABLE_SUFFIX BETWEEN '20260101' AND '20260131'
GROUP BY event_date
ORDER BY event_date"""
    
    if "w_bq_sql" not in st.session_state:
        st.session_state["w_bq_sql"] = lp.get("sql", sample_sql) if lp.get("source", "").lower() == "bigquery" else sample_sql
    
    sql = st.text_area("SQL", height=200, key="w_bq_sql")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§è¡¨ç¤º
    if bq_project:
        with st.expander("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§"):
            try:
                datasets = get_bq_datasets(bq_project)
                if datasets:
                    st.write(", ".join(datasets))
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            except Exception as e:
                st.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
if execute_btn or auto_execute_pending or (file_just_updated and st.session_state.get("auto_execute", False)):
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
        try:
            if source == "GA4":
                df = execute_ga4_query(
                    property_id,
                    start_date.strftime("%Y-%m-%d"),
                    end_date.strftime("%Y-%m-%d"),
                    dimensions,
                    metrics,
                    filter_d,
                    limit
                )
            elif source == "GSC":
                gsc_dimension_filter = parse_gsc_filter(gsc_filter) if 'gsc_filter' in dir() else None
                df = execute_gsc_query(
                    site_url,
                    start_date.strftime("%Y-%m-%d"),
                    end_date.strftime("%Y-%m-%d"),
                    dimensions,
                    limit,
                    gsc_dimension_filter
                )
            else:
                # BigQuery
                if not bq_project:
                    st.error("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    df = None
                elif not sql.strip():
                    st.error("SQLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    df = None
                else:
                    df = execute_bq_query(bq_project, sql)
            
            if df is not None and not df.empty:
                st.success(f"âœ“ {len(df):,} è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
                st.session_state["df"] = df
            elif df is not None:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# çµæœè¡¨ç¤º
if "df" in st.session_state:
    df = st.session_state["df"]
    
    # ã‚¿ãƒ–
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«", "ğŸ“ˆ ãƒãƒ£ãƒ¼ãƒˆ", "ğŸ’¾ ä¿å­˜"])
    
    with tab1:
        st.dataframe(df, use_container_width=True, height=400)
        
        # çµ±è¨ˆæƒ…å ±
        with st.expander("çµ±è¨ˆæƒ…å ±"):
            st.write(df.describe())
    
    with tab2:
        if len(df.columns) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                x_col = st.selectbox("Xè»¸", df.columns)
            with col2:
                y_col = st.selectbox("Yè»¸", [c for c in df.columns if c != x_col])
            
            chart_type = st.radio("ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—", ["æŠ˜ã‚Œç·š", "æ£’ã‚°ãƒ©ãƒ•"], horizontal=True)
            
            if chart_type == "æŠ˜ã‚Œç·š":
                st.line_chart(df.set_index(x_col)[y_col])
            else:
                st.bar_chart(df.set_index(x_col)[y_col])
    
    with tab3:
        st.subheader("ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜")
        col1, col2 = st.columns(2)
        with col1:
            # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                csv,
                f"data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "text/csv",
                use_container_width=True
            )
        with col2:
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            if st.button("ğŸ’¾ output/ ã«ä¿å­˜", use_container_width=True):
                import os
                os.makedirs("output", exist_ok=True)
                filepath = f"output/result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
                st.success(f"ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        
        st.divider()
        st.subheader("Google Sheets ã«ä¿å­˜")
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL
        sheet_url = st.text_input(
            "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL",
            placeholder="https://docs.google.com/spreadsheets/d/xxxxx",
            key="w_sheet_url"
        )
        
        col1, col2 = st.columns(2)
        with col1:
            sheet_name = st.text_input("ã‚·ãƒ¼ãƒˆå", value="data", key="w_sheet_name")
        with col2:
            save_mode = st.selectbox("ä¿å­˜ãƒ¢ãƒ¼ãƒ‰", ["ä¸Šæ›¸ã", "è¿½è¨˜", "ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ"], key="w_save_mode")
        
        # ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆæ™‚ã®ã‚­ãƒ¼åˆ—
        if save_mode == "ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ":
            key_cols = st.multiselect("ã‚­ãƒ¼åˆ—", df.columns.tolist(), key="w_upsert_keys")
        
        if st.button("ğŸ“¤ Google Sheets ã«ä¿å­˜", use_container_width=True, type="primary"):
            if not sheet_url:
                st.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                try:
                    mode_map = {"ä¸Šæ›¸ã": "overwrite", "è¿½è¨˜": "append", "ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ": "upsert"}
                    mode = mode_map[save_mode]
                    
                    if mode == "upsert" and not key_cols:
                        st.error("ã‚­ãƒ¼åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    else:
                        save_to_sheet(sheet_url, sheet_name, df, mode=mode, keys=key_cols if mode == "upsert" else None)
                        st.success(f"âœ“ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã«ä¿å­˜ã—ã¾ã—ãŸ")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# JSONãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆAI Agenté€£æºç”¨ï¼‰
with st.sidebar:
    with st.expander("ğŸ¤– JSON (AI Agentç”¨)"):
        if source == "GA4":
            params = {
                "source": "ga4",
                "property_id": property_id if 'property_id' in dir() else "",
                "date_range": {
                    "start": start_date.strftime("%Y-%m-%d"),
                    "end": end_date.strftime("%Y-%m-%d")
                },
                "dimensions": dimensions if 'dimensions' in dir() else [],
                "metrics": metrics if 'metrics' in dir() else [],
                "filter_d": filter_d if 'filter_d' in dir() else "",
                "limit": limit
            }
        elif source == "GSC":
            params = {
                "source": "gsc",
                "site_url": site_url if 'site_url' in dir() else "",
                "date_range": {
                    "start": start_date.strftime("%Y-%m-%d"),
                    "end": end_date.strftime("%Y-%m-%d")
                },
                "dimensions": dimensions if 'dimensions' in dir() else [],
                "filter": gsc_filter if 'gsc_filter' in dir() else "",
                "limit": limit
            }
        else:
            params = {
                "source": "bigquery",
                "project_id": bq_project if 'bq_project' in dir() else "",
                "sql": sql if 'sql' in dir() else ""
            }
        st.code(json.dumps(params, indent=2, ensure_ascii=False), language="json")
